x = ['codeparrot/apps_metric',
'lvwerra/test',
'angelina-wang/directional_bias_amplification',
'cpllab/syntaxgym',
'lvwerra/bary_score',
'hack/test_metric',
'yzha/ctc_eval',
'mfumanelli/geometric_mean',
'daiyizheng/valid',
'erntkn/dice_coefficient',
'mgfrantz/roc_auc_macro',
'Vlasta/pr_auc',
'gorkaartola/metric_for_tp_fp_samples',
'idsedykh/metric',
'idsedykh/codebleu2',
'idsedykh/codebleu',
'idsedykh/megaglue',
'Vertaix/vendiscore',
'GMFTBY/dailydialogevaluate',
'GMFTBY/dailydialog_evaluate',
'jzm-mailchimp/joshs_second_test_metric',
'ola13/precision_at_k',
'yulong-me/yl_metric',
'abidlabs/mean_iou',
'abidlabs/mean_iou2',
'KevinSpaghetti/accuracyk',
'NimaBoscarino/weat',
'ronaldahmed/nwentfaithfulness',
'Viona/infolm',
'kyokote/my_metric2',
'kashif/mape',
'Ochiroo/rouge_mn',
'leslyarun/fbeta_score',
'anz2/iliauniiccocrevaluation',
'zbeloki/m2',
'xu1998hz/sescore',
'dvitel/codebleu',
'NCSOFT/harim_plus',
'JP-SystemsX/nDCG',
'sportlosos/sescore',
'Drunper/metrica_tesi',
'jpxkqx/peak_signal_to_noise_ratio',
'jpxkqx/signal_to_reconstruction_error',
'hpi-dhc/FairEval',
'lvwerra/accuracy_score',
'ybelkada/cocoevaluate',
'harshhpareek/bertscore',
'posicube/mean_reciprocal_rank',
'bstrai/classification_report',
'omidf/squad_precision_recall',
'Josh98/nl2bash_m',
'BucketHeadP65/confusion_matrix',
'BucketHeadP65/roc_curve',
'yonting/average_precision_score',
'transZ/test_parascore',
'transZ/sbert_cosine',
'hynky/sklearn_proxy',
'xu1998hz/sescore_english_mt',
'xu1998hz/sescore_german_mt',
'xu1998hz/sescore_english_coco',
'xu1998hz/sescore_english_webnlg',
'unnati/kendall_tau_distance',
'Viona/fuzzy_reordering',
'Viona/kendall_tau',
'lhy/hamming_loss',
'lhy/ranking_loss',
'Muennighoff/code_eval_octopack',
'yuyijiong/quad_match_score',
'AlhitawiMohammed22/CER_Hu-Evaluation-Metrics',
'Yeshwant123/mcc',
'phonemetransformers/segmentation_scores',
'sma2023/wil',
'chanelcolgate/average_precision',
'ckb/unigram',
'Felipehonorato/eer',
'manueldeprada/beer',
'shunzh/apps_metric',
'He-Xingwei/sari_metric',
'langdonholmes/cohen_weighted_kappa',
'fschlatt/ner_eval',
'hyperml/balanced_accuracy',
'brian920128/doc_retrieve_metrics',
'guydav/restrictedpython_code_eval',
'k4black/codebleu',
'Natooz/ece',
'ingyu/klue_mrc',
'Vipitis/shadermatch',
'gabeorlanski/bc_eval',
'jjkim0807/code_eval',
'repllabs/mean_reciprocal_rank',
'repllabs/mean_average_precision',
'mtc/fragments',
'DarrenChensformer/eval_keyphrase',
'kedudzic/charmatch',
'Vallp/ter',
'DarrenChensformer/relation_extraction',
'Ikala-allen/relation_extraction',
'danieldux/hierarchical_softmax_loss',
'nlpln/tst',
'bdsaglam/jer',
'davebulaval/meaningbert',
'fnvls/bleu1234',
'fnvls/bleu_1234',
'nevikw39/specificity',
'yqsong/execution_accuracy',
'shalakasatheesh/squad_v2',
'arthurvqin/pr_auc',
'd-matrix/dmx_perplexity',
'akki2825/accents_unplugged_eval',
'juliakaczor/accents_unplugged_eval',
'Vickyage/accents_unplugged_eval',
'Qui-nn/accents_unplugged_eval',
'TelEl/accents_unplugged_eval',
'livvie/accents_unplugged_eval',
'DaliaCaRo/accents_unplugged_eval',
'alvinasvk/accents_unplugged_eval',
'LottieW/accents_unplugged_eval',
'LuckiestOne/valid_efficiency_score',
'Fritz02/execution_accuracy',
'huanghuayu/multiclass_brier_score',
'jialinsong/apps_metric',
'DoctorSlimm/bangalore_score',
'agkphysics/ccc',
'DoctorSlimm/kaushiks_criteria',
'CZLC/rouge_raw',
'bascobasculino/mot-metrics',
'SEA-AI/mot-metrics',
'SEA-AI/det-metrics',
'saicharan2804/my_metric',
'red1bluelost/evaluate_genericify_cpp',
'maksymdolgikh/seqeval_with_fbeta',
'Bekhouche/NED',
'danieldux/isco_hierarchical_accuracy',
'ginic/phone_errors',
'berkatil/map',
'DarrenChensformer/action_generation',
'buelfhood/fbeta_score',
'danasone/ru_errant',
'helena-balabin/youden_index',
'SEA-AI/panoptic-quality',
'SEA-AI/box-metrics',
'MathewShen/bleu',
'berkatil/mrr',
'BridgeAI-Lab/SemF1',
'SEA-AI/horizon-metrics',
'maysonma/lingo_judge_metric',
'dannashao/span_metric',
'Aye10032/loss_metric',
'ag2435/my_metric',
'kilian-group/arxiv_score',
'bomjin/code_eval_octopack',
'svenwey/logmetric',
'bowdbeg/matching_series',
'BridgeAI-Lab/Sem-nCG',
'bowdbeg/patch_series',
'venkatasg/gleu',
'kbmlcoding/apps_metric',
'jijihuny/ecqa',
'prajwall/mse',
'd-matrix/dmxMetric',
'dotkaio/competition_math',
'bowdbeg/docred',
'Remeris/rouge_ru',
'jarod0411/aucpr',
'Ruchin/jaccard_similarity',
'phucdev/blanc_score',
'NathanMad/bertscore-with-torch_dtype',
'cointegrated/blaser_2_0_qe',
'ahnyeonchan/Alignment-and-Uniformity',
'Baleegh/Fluency_Score',
'mdocekal/multi_label_precision_recall_accuracy_fscore',
'phucdev/vihsd',
'argmaxinc/detailed-wer',
'SEA-AI/user-friendly-metrics',
'hage2000/code_eval_stdio',
'hage2000/my_metric',
'Natooz/levenshtein',
'Khaliq88/execution_accuracy',
'pico-lm/perplexity',
'mtzig/cross_entropy_loss',
'kiracurrie22/precision',
'openpecha/bleurt',
'SEA-AI/ref-metrics',
'Natooz/mse',
'buelfhood/fbeta_score_2',
'murinj/hter',
'nobody4/waf_metric',
'mdocekal/precision_recall_fscore_accuracy',
'Glazkov/mars',
'Aye10032/top5_error_rate',
'ncoop57/levenshtein_distance',
'kaleidophon/almost_stochastic_order',
'NeuraFusionAI/Arabic-Evaluation',
'lvwerra/element_count',
'prb977/cooccurrence_count',
'NimaBoscarino/pseudo_perplexity',
'ybelkada/toxicity',
'ronaldahmed/ccl_win',
'christopher/tokens_per_byte',
'lsy641/distinct',
'grepLeigh/perplexity',
'Charles95/element_count',
'Charles95/accuracy',
'Lucky28/honest']
import evaluate
evaluate.list_evaluation_modules